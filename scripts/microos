#!/usr/bin/env python3
"""Read the MicroOS repository and translate the RPM packages into Yocto packages"""
import argparse
import fileinput
import gzip
import pathlib
import re
import shutil
import subprocess
import sys
import urllib.error
import urllib.parse
import urllib.request
import xml.etree.ElementTree as ET
from dataclasses import dataclass


REPO = {
    "x86_64": "https://download.opensuse.org/tumbleweed/repo/oss/",
    "aarch64": "https://download.opensuse.org/ports/aarch64/tumbleweed/repo/oss/",
}


@dataclass
class Package:
    name: str
    pv: str
    summary: str
    description: str
    src_uri: str
    sha512sum: str
    license: str
    rprovides: list[str]
    rdepends: list[str]


def update_group(group):
    try:
        print(f"Updating {group} from OBS ... ")
        result = subprocess.run(
            ["osc", "cat", "openSUSE:Factory", "000product/opensuse_microos.group"],
            capture_output=True,
        )
    except FileNotFoundError:
        print("'osc' command not found. Install it or download manually the group")
        sys.exit(1)

    if result.returncode:
        print("Error downloading the group")
        sys.exit(1)

    with group.open("wb") as f:
        f.write(result.stdout)


def read_and_parse(url):
    with urllib.request.urlopen(url) as resp:
        if url.endswith(".gz"):
            return ET.parse(gzip.open(resp)).getroot()
        else:
            return ET.parse(resp).getroot()


def primary_xml(url):
    repomd_url = urllib.parse.urljoin(url, "repodata/repomd.xml")
    print("Reading repomd.xml ...")
    repomd_xml = read_and_parse(repomd_url)
    location = repomd_xml.find(
        "./{http://linux.duke.edu/metadata/repo}data[@type='primary']/"
        "{http://linux.duke.edu/metadata/repo}location"
    )
    if location is None:
        print("Error. Primary location tag not found", file=sys.stderr)
        return []
    primary_url = urllib.parse.urljoin(url, location.attrib["href"])
    print("Reading primary.xml ...")
    return read_and_parse(primary_url)


def generate_package_list(url):
    packages_xml = primary_xml(url).findall(
        "./{http://linux.duke.edu/metadata/common}package[@type='rpm']"
    )
    print(f"Found {len(packages_xml)} packages")

    packages = []

    print("Generating package list ...")
    for package_xml in packages_xml:
        name = package_xml.find("{http://linux.duke.edu/metadata/common}name").text
        version = package_xml.find(
            "{http://linux.duke.edu/metadata/common}version"
        ).attrib["ver"]
        checksum = package_xml.find(
            "{http://linux.duke.edu/metadata/common}checksum"
        ).text
        summary = package_xml.find(
            "{http://linux.duke.edu/metadata/common}summary"
        ).text
        description = package_xml.find(
            "{http://linux.duke.edu/metadata/common}description"
        ).text
        location = package_xml.find(
            "{http://linux.duke.edu/metadata/common}location"
        ).attrib["href"]
        location = urllib.parse.urljoin(url, location)
        license = package_xml.find(
            "{http://linux.duke.edu/metadata/common}format/"
            "{http://linux.duke.edu/metadata/rpm}license"
        ).text
        provides = package_xml.findall(
            "{http://linux.duke.edu/metadata/common}format/"
            "{http://linux.duke.edu/metadata/rpm}provides/"
            "{http://linux.duke.edu/metadata/rpm}entry"
        )
        provides = [entry.attrib["name"] for entry in provides]
        requires = package_xml.findall(
            "{http://linux.duke.edu/metadata/common}format/"
            "{http://linux.duke.edu/metadata/rpm}requires/"
            "{http://linux.duke.edu/metadata/rpm}entry"
        )
        requires = [entry.attrib["name"] for entry in requires]

        packages.append(
            Package(
                name=name,
                pv=version,
                summary=summary,
                description=description,
                src_uri=location,
                sha512sum=checksum,
                license=license,
                rprovides=provides,
                rdepends=requires,
            )
        )

    return packages


def normalize_pn(name):
    return name.lower().replace("_", "-")


def normalize_text(text):
    text = text.replace('"', "'").replace("\\", "\\\\")
    return " \\\n".join(line for line in text.split("\n"))


def license(lic):
    return (
        lic.replace(" AND ", " & ")
        .replace(" and ", " & ")
        .replace(" OR ", " | ")
        .replace(" or ", " | ")
        .replace(" WITH ", "-WITH-")
        .replace(" with ", "-WITH-")
    )


def normalize_pkgs(pkgs):
    prefixes = [
        "application(",
        "metainfo(",
        "mimehandler(",
        "weakremover(",
    ]

    def _remove_versioned_symbol(pkg):
        return re.sub(r"\(.*\)\(64bit\)", "", pkg)

    def _remove_arch(pkg):
        return pkg.replace("(aarch-64)", "")

    def _replace_parens(pkg):
        return re.sub(r"\((.*)\)", r"-\1", pkg)

    def _replace_char(pkg):
        return pkg.replace("_", "-").replace(":", "-")

    def _add_usr(pkg):
        return f"/usr{pkg}" if pkg.startswith("/bin/") else pkg

    def _normalize(pkg):
        return _add_usr(
            _replace_char(_replace_parens(_remove_arch(_remove_versioned_symbol(pkg))))
        )

    def _ignore_prefix(pkg):
        return any(pkg.startswith(prefix) for prefix in prefixes)

    def _ignore_bool(pkg):
        return any(f" {cond} " in pkg for cond in ("if", "or"))

    def _ignore(pkg):
        return _ignore_prefix(pkg) or _ignore_bool(pkg)

    return " \\\n".join(
        sorted(set(_normalize(pkg) for pkg in pkgs if not _ignore(pkg)))
    )


def update_pool(pool, packages):
    for package in packages:
        recipe = pool / package.name
        recipe.mkdir(exist_ok=True)
        with (recipe / f"{normalize_pn(package.name)}.bb").open("w") as f:
            if package.summary:
                f.write(f'SUMMARY = "{normalize_text(package.summary)}"\n')
            if package.description:
                f.write(f'DESCRIPTION = "{normalize_text(package.description)}"\n')
            f.write(f'LICENSE = "{license(package.license)}"\n')
            f.write("\n")
            f.write(f'PV = "{package.pv}"\n')
            f.write("\n")
            path = pathlib.Path(urllib.parse.urlparse(package.src_uri).path)
            f.write(f'RPM_NAME = "{path.name}"\n')
            f.write(f'RPM_HASH = "{package.sha512sum}"\n')
            arch = path.parent.name
            if arch != "aarch64":
                f.write(f'REPO_ARCH = "{arch}"\n')
            f.write("\n")
            f.write(f'RPROVIDES:${{PN}} += "{normalize_pkgs(package.rprovides)}"\n')
            f.write("\n")
            f.write(f'RDEPENDS:${{PN}} += "{normalize_pkgs(package.rdepends)}"\n')
            f.write("\n")
            f.write("inherit rpm\n")


def prune_pool(pool, packages):
    packages = {p.name for p in packages}
    for r in pool.iterdir():
        if r.is_dir() and r.name not in packages:
            shutil.rmtree(r)


def generate_group_package_list(group):
    with group.open() as f:
        partial = f.read()

    root = ET.fromstring(f"<grp>{partial}</grp>")

    return [pkg.attrib["name"] for pkg in root.findall(".//package")]


def unlink_recipes(recipes):
    for r in recipes.iterdir():
        if r.is_symlink():
            r.unlink()


def link_recipes(recipes, group_packages, pool):
    print("Linking recipes from the pool ...")
    rel_pool = pathlib.Path("..", pool)
    for package in group_packages:
        if (pool / package).exists():
            (recipes / package).symlink_to(rel_pool / package)


def release_version(packages, release_pkg):
    for pkg in packages:
        if pkg.name == release_pkg:
            return pkg.pv


def update_distro_version(version):
    with fileinput.input("./conf/distro/microos.conf", inplace=True) as f:
        for line in f:
            if line.startswith("DISTRO_VERSION"):
                print(f'DISTRO_VERSION = "{version}"')
            else:
                print(line, end="")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Syncronize MicroOS repository")
    parser.add_argument(
        "-a",
        "--arch",
        default="aarch64",
        choices=REPO.keys(),
        help="Select repository architecture (default: aarch64)",
    )
    parser.add_argument(
        "-p",
        "--pool",
        default="pool-tumbleweed",
        type=pathlib.Path,
        help="Pool of Yocto packages that represent all Tumbleweed (default: pool-tumbleweed)",
    )
    parser.add_argument(
        "-r",
        "--recipes",
        default="recipes-microos",
        type=pathlib.Path,
        help="Yocto recipe directory to synchronize (default: recipes-microos)",
    )
    parser.add_argument(
        "-g",
        "--group",
        default="recipes-microos/opensuse_microos.group",
        type=pathlib.Path,
        help=(
            "Pool of Yocto packages that represent all Tumbleweed "
            "(default: recipes-microos/opensuse_microos.group"
        ),
    )
    parser.add_argument(
        "-u",
        "--update-group",
        action="store_true",
        help="Use 'osc' to update the MicroOS group",
    )
    parser.add_argument(
        "-k",
        "--release-pkg",
        default="MicroOS-release",
        help="Package that contains the release version (default: MicroOS-release)",
    )

    args = parser.parse_args()

    if args.update_group:
        update_group(args.group)

    packages = generate_package_list(REPO[args.arch])
    update_pool(args.pool, packages)
    prune_pool(args.pool, packages)

    group_packages = generate_group_package_list(args.group)
    unlink_recipes(args.recipes)
    link_recipes(args.recipes, group_packages, args.pool)

    version = release_version(packages, args.release_pkg)
    if version:
        update_distro_version(version)
    else:
        print("Release version not found")
